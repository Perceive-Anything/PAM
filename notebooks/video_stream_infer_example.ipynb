{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from PIL import Image\n",
    "from typing import Dict, Optional, Sequence, List\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import tokenizer_image_token, process_images, get_model_name_from_path\n",
    "from mask_vis_tools import save_mask, save_box, save_points\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Task Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_modes = {\n",
    "    \"video_cap_en\": \"<image>\\nProvide a caption for this subject in this video.\\nPrevious caption: {history}\",\n",
    "    \"video_cap_ch\": \"<image>\\n对该视频中的目标对象提供一个描述。\\n历史描述：{history}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "model_path = \"path/to/PAM-ckpt\"\n",
    "\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(\n",
    "    model_path=model_path,\n",
    "    model_base=None,\n",
    "    model_name=get_model_name_from_path(model_path),\n",
    "    multimodal=True,\n",
    "    torch_dtype=\"bfloat16\", # bfloat16, float16\n",
    "    device_map=\"cuda\"\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "temperature = 0.1\n",
    "top_p = None\n",
    "num_beams = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the 'python videos/extract_mp4_frames.py' to extract the frames(.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = \"videos/02_juggle\"\n",
    "sample_num = 96\n",
    "# scan all the JPEG frame names in this directory\n",
    "frames = [\n",
    "    p for p in os.listdir(video_dir)\n",
    "    if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "]\n",
    "frames.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
    "indices = np.linspace(0, len(frames) - 1, num=sample_num, dtype=int)\n",
    "frames = [os.path.join(video_dir, frames[i]) for i in indices]\n",
    "print(frames)\n",
    "\n",
    "# take a look the first video frame\n",
    "frame_idx = 0\n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.title(f\"frame {frame_idx}\")\n",
    "plt.imshow(Image.open(frames[frame_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying a specific object with a box. The model takes a box as input, provided in xyxy format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(mask_array, type=\"xyxy\"):\n",
    "\n",
    "    if mask_array.dtype != np.uint8:\n",
    "        mask_uint8 = mask_array.astype(np.uint8)\n",
    "    else:\n",
    "        mask_uint8 = mask_array\n",
    "\n",
    "    contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if not contours:\n",
    "        return None\n",
    "\n",
    "    all_points = np.concatenate(contours, axis=0)\n",
    "    if all_points.size == 0:\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(all_points)\n",
    "    if type == \"xyxy\":\n",
    "        return [int(x), int(y), int(x)+int(w), int(y)+int(h)]\n",
    "    else:\n",
    "        return [int(x), int(y), int(w), int(h)]\n",
    "\n",
    "### prompting box for the first frame\n",
    "bbox_xywh = [587, 32, 251, 650]\n",
    "x1, y1 = int(bbox_xywh[0]), int(bbox_xywh[1])\n",
    "x2, y2 = int(bbox_xywh[0] + bbox_xywh[2]), int(bbox_xywh[1] + bbox_xywh[3])\n",
    "bbox_xyxy = [x1, y1, x2, y2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate semantic outputs and mask outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define decoding timesteps\n",
    "DECODING_TIMESTEPS = [32, 64, 96]\n",
    "PROMPT_TEMPLATE = task_modes[\"video_cap_en\"]\n",
    "\n",
    "for segment_idx, current_segment_end_frame in enumerate(DECODING_TIMESTEPS):\n",
    "    print(f\"\\n--- Processing Segment {segment_idx + 1} ---\")\n",
    "    if segment_idx == 0:\n",
    "        segment_start_frame = 0\n",
    "        visual_prompt = bbox_xyxy\n",
    "        vp_labels = None\n",
    "        task_prompt = PROMPT_TEMPLATE.replace(\"{history}\", \"None\")\n",
    "    else:\n",
    "        segment_start_frame = DECODING_TIMESTEPS[segment_idx - 1]\n",
    "        visual_prompt = last_segment_bbox_xyxy\n",
    "        vp_labels = None\n",
    "        task_prompt = PROMPT_TEMPLATE.replace(\"{history}\", history)\n",
    "\n",
    "    current_frames = frames[segment_start_frame:current_segment_end_frame]\n",
    "\n",
    "    \n",
    "    conv = conv_templates[\"qwen_2\"].copy()\n",
    "    conv.append_message(conv.roles[0], task_prompt)\n",
    "    conv.append_message(conv.roles[1], None)\n",
    "    prompt = conv.get_prompt()\n",
    "    input_ids = tokenizer_image_token(prompt, tokenizer, IMAGE_TOKEN_INDEX, return_tensors='pt').unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        output_ids, all_masks_logits, all_scores = model.generate(\n",
    "            input_ids,\n",
    "            images=[current_frames],\n",
    "            visual_prompts=[visual_prompts],\n",
    "            vp_labels=[vp_labels],\n",
    "            types=['video'],\n",
    "            do_sample=True if temperature > 0 else False,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            num_beams=num_beams,\n",
    "            max_new_tokens=512,\n",
    "            use_cache=True)\n",
    "\n",
    "    outputs = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0].strip()\n",
    "    history = outputs\n",
    "    print(f\"Frames: {segment_start_frame} to {current_segment_end_frame - 1}\")\n",
    "    print(\"Prediction: \", outputs)\n",
    "\n",
    "    vis_frame_stride = 8\n",
    "    for out_frame_idx in range(len(current_frames)):\n",
    "        if out_frame_idx % vis_frame_stride == 0 or out_frame_idx == len(current_frames) - 1:\n",
    "            img = Image.open(current_frames[out_frame_idx]).convert('RGB')\n",
    "            img = np.array(img)\n",
    "            fig, ax = plt.subplots(figsize=(9, 6))\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"Segment {segment_idx + 1}, frame {segment_start_frame + out_frame_idx}, mask score: {all_scores[0][out_frame_idx]}\")\n",
    "            for i, mask in enumerate(all_masks_logits[0][out_frame_idx][1]):\n",
    "                save_mask(mask, ax, borders=True)\n",
    "            if segment_idx == 0 and out_frame_idx == 0:\n",
    "                save_box(visual_prompts, ax)\n",
    "            if out_frame_idx == len(current_frames) - 1:\n",
    "                last_segment_bbox_xyxy = get_bounding_box(mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
